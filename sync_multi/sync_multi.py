#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
import time
import json
import logging
import fnmatch
import threading
import signal
import tempfile
import shutil
import platform
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from watchdog.events import FileSystemEventHandler

# â€”â€” Observer é€‰æ‹©ï¼ˆmacOS ç”¨è½®è¯¢ï¼Œå…¶ä»–ç³»ç»Ÿç”¨é»˜è®¤ï¼‰å–µâ™¡ï½
if platform.system() == 'Darwin':
    from watchdog.observers.polling import PollingObserver as ObserverClass
else:
    from watchdog.observers import Observer as ObserverClass

# â€”â€” é…ç½® & å»æŠ–å»¶è¿Ÿï¼ˆç§’ï¼‰å–µâ™¡ï½
CFG_PATH = Path("config.json")
DEBOUNCE = 1.0

# â€”â€” è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼åŒ–å™¨ â€”â€” å–µâ™¡ï½
class SimpleFormatter(logging.Formatter):
    def format(self, record):
        ct = self.formatTime(record, "%Y-%m-%d %H:%M:%S")
        lvl = record.levelname
        msg = record.getMessage()
        return f"{ct} | {lvl:^5} | {msg}"

# â€”â€” è¯»å– & æ ¡éªŒé…ç½® â€”â€” å–µâ™¡ï½
if not CFG_PATH.exists():
    print(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°ï¼š{CFG_PATH}ï¼Œè¯·å…ˆåˆ›å»ºå–µâ™¡ï½")
    sys.exit(1)

cfg = json.loads(CFG_PATH.read_text(encoding='utf-8'))
tasks_cfg = cfg.get("tasks", [])
if not isinstance(tasks_cfg, list) or not tasks_cfg:
    print("config.json ä¸­ tasks åº”ä¸ºéç©ºåˆ—è¡¨å–µâ™¡ï½")
    sys.exit(1)

# â€”â€” å…¨å±€åœæ­¢æ ‡å¿— & ä¿¡å·å¤„ç† â€”â€” å–µâ™¡ï½
stop_event = threading.Event()
def _handle(signum, frame):
    stop_event.set()
    print("\næ”¶åˆ°é€€å‡ºä¿¡å·ï½å‡†å¤‡åœæ­¢å–µâ™¡ï½")
for sig in ("SIGINT", "SIGTERM"):
    if hasattr(signal, sig):
        signal.signal(getattr(signal, sig), _handle)

# â€”â€” é‡è¯•è£…é¥°å™¨ â€”â€” å–µâ™¡ï½
def retry(times=3, delay=0.5):
    def deco(fn):
        def wrapper(*a, **kw):
            for i in range(times):
                try:
                    return fn(*a, **kw)
                except Exception as e:
                    if i < times - 1:
                        time.sleep(delay)
                    else:
                        raise
        return wrapper
    return deco

# â€”â€” åŒæ­¥ä»»åŠ¡ç±» â€”â€” å–µâ™¡ï½
class SyncTask:
    def __init__(self, cfg):
        self.name    = cfg.get("name", "sync_task")
        # sources/targets æ”¯æŒå•æ¡æˆ–å¤šæ¡
        self.sources = [Path(p) for p in (cfg.get("sources") or [cfg.get("source")])]
        self.targets = [Path(p) for p in (cfg.get("targets") or [cfg.get("target")])]
        self.exclude = cfg.get("exclude", [])
        self.workers = cfg.get("workers", 4)
        self.logfile = Path(cfg.get("log", f"logs/{self.name}.log"))
        self._validate()
        self._setup_logger()
        self._lock = threading.Lock()
        self._timer = None

    def _validate(self):
        if not self.sources or not self.targets:
            raise ValueError(f"ä»»åŠ¡ã€Œ{self.name}ã€éœ€è‡³å°‘ä¸€ä¸ªæºå’Œä¸€ä¸ªç›®æ ‡å–µâ™¡ï½")
        # æ£€æŸ¥æºç›®å½•å­˜åœ¨
        for s in self.sources:
            if not s.is_dir():
                raise ValueError(f"æºç›®å½•ä¸å­˜åœ¨ï¼š{s} å–µâ™¡ï½")
        # æ£€æŸ¥ç›®æ ‡ç›®å½•å¯å†™
        for t in self.targets:
            t.mkdir(parents=True, exist_ok=True)
            test = t / f".sync_test_{int(time.time())}"
            try:
                test.write_text("ok")
                test.unlink()
            except Exception as e:
                raise ValueError(f"ç›®æ ‡ä¸å¯å†™ï¼š{t}ï¼›{e} å–µâ™¡ï½")
        # å¦‚æœå¤šæºå¤šç›®æ ‡ï¼Œé•¿åº¦è¦ä¸€è‡´
        if len(self.sources) > 1 and len(self.targets) > 1 and len(self.sources) != len(self.targets):
            raise ValueError("æºä¸ç›®æ ‡æ•°é‡ä¸åŒ¹é…å–µâ™¡ï½")

    def _setup_logger(self):
        self.logfile.parent.mkdir(parents=True, exist_ok=True)
        self.logger = logging.getLogger(self.name)
        self.logger.setLevel(logging.INFO)
        if not self.logger.handlers:
            fmt = SimpleFormatter()
            fh  = logging.FileHandler(self.logfile, encoding='utf-8')
            sh  = logging.StreamHandler()
            fh.setFormatter(fmt); sh.setFormatter(fmt)
            self.logger.addHandler(fh); self.logger.addHandler(sh)
        # ä¼˜é›…æ‰“å°å¯åŠ¨ä¿¡æ¯
        srcs = ", ".join(str(p) for p in self.sources)
        tgts = ", ".join(str(p) for p in self.targets)
        self.logger.info(f"ğŸŸ¢ å¯åŠ¨ä»»åŠ¡ã€Œ{self.name}ã€\n"
                         f"    Sources: {srcs}\n"
                         f"    Targets: {tgts}\n"
                         f"    Exclude: {self.exclude}\n"
                         f"    Workers: {self.workers}")

    def should_exclude(self, path: Path, base: Path):
        rel = path.relative_to(base).as_posix()
        return any(fnmatch.fnmatch(rel, pat) for pat in self.exclude)

    def _pairs(self):
        if len(self.sources) == len(self.targets):
            return list(zip(self.sources, self.targets))
        if len(self.sources) == 1:
            return [(self.sources[0], t) for t in self.targets]
        return [(s, self.targets[0]) for s in self.sources]

    @retry(times=3, delay=0.3)
    def _atomic_copy(self, src: Path, dst: Path):
        dst.parent.mkdir(parents=True, exist_ok=True)
        # åœ¨ç›®æ ‡ç›®å½•ä¸‹åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä»¥ä¿è¯åŸå­æ€§
        with tempfile.NamedTemporaryFile(dir=dst.parent, delete=False) as tmp:
            tmp.write(src.read_bytes())
            tmp.flush()
        Path(tmp.name).replace(dst)

    @retry(times=3, delay=0.3)
    def _safe_delete(self, path: Path):
        if path.is_dir():
            path.rmdir()
        else:
            path.unlink()

    def gather(self):
        to_copy, to_delete = [], []
        for s_base, t_base in self._pairs():
            # éå†æºï¼šæ–°å¢/æ›´æ–°
            for src in s_base.rglob("*"):
                if src.is_file() and not self.should_exclude(src, s_base):
                    dst = t_base / src.relative_to(s_base)
                    if not dst.exists() or src.stat().st_mtime > dst.stat().st_mtime:
                        to_copy.append((src, dst))
            # éå†ç›®æ ‡ï¼šåˆ é™¤å¤šä½™
            for dst in t_base.rglob("*"):
                rel = dst.relative_to(t_base)
                src = s_base / rel
                if not src.exists():
                    to_delete.append(dst)
        return to_copy, to_delete

    def sync(self):
        # åŒæ­¥é”ï¼Œé¿å…é‡å¤è§¦å‘
        if not self._lock.acquire(False):
            return
        try:
            copies, deletes = self.gather()
            with ThreadPoolExecutor(max_workers=self.workers) as pool:
                futures = [pool.submit(self._atomic_copy, s, d) for s, d in copies] + \
                          [pool.submit(self._safe_delete, p) for p in deletes]
                for _ in as_completed(futures):
                    pass
            # åªæœ‰æœ‰å˜åŠ¨æ—¶æ‰è¾“å‡ºâœ…ï¼Œå¦åˆ™é™é»˜
            if copies or deletes:
                self.logger.info(f"âœ… åŒæ­¥å®Œæˆï¼šå¤åˆ¶ {len(copies)}ï¼Œåˆ é™¤ {len(deletes)}")
        except Exception as e:
            self.logger.error(f"åŒæ­¥å‡ºé”™ï¼š{e}", exc_info=True)
        finally:
            self._lock.release()

    class Handler(FileSystemEventHandler):
        def __init__(self, task):
            self.task = task
        def on_any_event(self, event):
            # å»æŠ–ï¼šæ¯æ¬¡äº‹ä»¶éƒ½é‡ç½®å®šæ—¶å™¨
            if self.task._timer and self.task._timer.is_alive():
                self.task._timer.cancel()
            self.task._timer = threading.Timer(DEBOUNCE, self.task.sync)
            self.task._timer.start()

    def start(self):
        self.sync()  # é¦–æ¬¡å…¨é‡åŒæ­¥
        obs = ObserverClass()
        for s in self.sources:
            obs.schedule(self.Handler(self), str(s), recursive=True)
        obs.start()
        return obs

# â€”â€” å¯åŠ¨æ‰€æœ‰ä»»åŠ¡ & ä¸»å¾ªç¯ â€”â€” å–µâ™¡ï½
observers = []
for tcfg in tasks_cfg:
    try:
        task = SyncTask(tcfg)
        observers.append(task.start())
    except Exception as e:
        print(f"ä»»åŠ¡ã€Œ{tcfg.get('name','?')}ã€åˆå§‹åŒ–å¤±è´¥ï¼š{e}")

try:
    while not stop_event.is_set():
        time.sleep(0.5)
finally:
    for o in observers:
        o.stop()
    print("æ‰€æœ‰ä»»åŠ¡å·²ä¼˜é›…åœæ­¢å–µâ™¡ï½")
